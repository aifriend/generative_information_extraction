_target_: pytorch_lightning.Trainer

gpus: 4
accelerator: "ddp"
replace_sampler_ddp: True
num_sanity_val_steps: 0

max_steps: 200000
val_check_interval: 40000 # 5000 * accumulate_grad_batch

weights_summary: null
progress_bar_refresh_rate: 5
resume_from_checkpoint: null

gradient_clip_val: 0.1
gradient_clip_algorithm: "norm"

accumulate_grad_batches: 4
# TODO: Update learning rate to achieve same behavior
# 2 GPUS * 4 samples per batch * 4 batches = 32 samples in each update step
